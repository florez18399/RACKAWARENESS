version: '3.8'

# Definimos los volúmenes "nombrados" para persistir los datos
# Esto es crucial. Si no lo hacemos, el NameNode se reformatearía
# cada vez y los DataNodes perderían sus bloques.
volumes:
  namenode-data:
  datanode-br-data:
  datanode-cl-data:
  datanode-co-data:

services:
  # ---------------------------------------------------
  # SERVICIO CENTRAL: NameNode
  # ---------------------------------------------------
  namenode:
    image: hadoop-base:3.2.1 # <-- Usando nuestra imagen custom
    container_name: namenode
    hostname: namenode
    # Conectamos el NameNode a TODAS las redes (zonas)
    # para que pueda hablar con todos los DataNodes y Clientes.
    networks:
      zona-br:
        ipv4_address: 172.20.1.10
      zona-cl:
        ipv4_address: 172.20.2.10
      zona-co:
        ipv4_address: 172.20.3.10
    ports:
      - "9870:9870" # UI Web del NameNode
      - "19000:9000" # Puerto del Filesystem
    volumes:
      # 1. Montamos la configuración de Hadoop desde nuestra carpeta local
      - ./config:/opt/hadoop/etc/hadoop
      # 2. Montamos el volumen nombrado para persistir los metadatos
      - namenode-data:/data/namenode
    # Este comando es la "magia" para producción:
    # 1. Inicia SSH (requerido por Hadoop)
    # 2. Revisa si el NameNode ya está formateado.
    # 3. Si no lo está (! -d .../current), lo formatea.
    # 4. Inicia el daemon del NameNode.
    command: >
      bash -c "
        /etc/init.d/ssh start &&
        if [ ! -d /data/namenode/current ]; then
          echo 'Formateando NameNode...'
          hdfs namenode -format -nonInteractive
        fi &&
        hdfs namenode
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://namenode:9870"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ---------------------------------------------------
  # ZONA 1: BRASIL (Rack: /zona/br)
  # ---------------------------------------------------
  datanode-br:
    image: hadoop-base:3.2.1
    container_name: datanode-br
    hostname: datanode-br
    # Conectado a todas las redes para la replicación
    networks:
      zona-br:
        ipv4_address: 172.20.1.11 # IP "local"
      zona-cl:
      zona-co:
    volumes:
      - ./config:/opt/hadoop/etc/hadoop
      - datanode-br-data:/data/datanode
    command: ["bash", "-c", "/etc/init.d/ssh start && hdfs datanode"]
    depends_on:
      namenode:
        condition: service_healthy # Espera a que el NameNode esté listo

  client-br:
    image: hadoop-base:3.2.1
    container_name: client-br
    hostname: client-br
    # El cliente SÓLO vive en su red local
    networks:
      zona-br:
        ipv4_address: 172.20.1.100
    volumes:
      - ./config:/opt/hadoop/etc/hadoop
    # Mantenemos el contenedor vivo para poder entrar con 'docker exec'
    command: ["bash", "-c", "/etc/init.d/ssh start && tail -f /dev/null"]

  # ---------------------------------------------------
  # ZONA 2: CHILE (Rack: /zona/cl)
  # ---------------------------------------------------
  datanode-cl:
    image: hadoop-base:3.2.1
    container_name: datanode-cl
    hostname: datanode-cl
    networks:
      zona-br:
      zona-cl:
        ipv4_address: 172.20.2.11 # IP "local"
      zona-co:
    volumes:
      - ./config:/opt/hadoop/etc/hadoop
      - datanode-cl-data:/data/datanode
    command: ["bash", "-c", "/etc/init.d/ssh start && hdfs datanode"]
    depends_on:
      namenode:
        condition: service_healthy

  client-cl:
    image: hadoop-base:3.2.1
    container_name: client-cl
    hostname: client-cl
    networks:
      zona-cl:
        ipv4_address: 172.20.2.100
    volumes:
      - ./config:/opt/hadoop/etc/hadoop
    command: ["bash", "-c", "/etc/init.d/ssh start && tail -f /dev/null"]

  # ---------------------------------------------------
  # ZONA 3: COLOMBIA (Rack: /zona/co)
  # ---------------------------------------------------
  datanode-co:
    image: hadoop-base:3.2.1
    container_name: datanode-co
    hostname: datanode-co
    networks:
      zona-br:
      zona-cl:
      zona-co:
        ipv4_address: 172.20.3.11 # IP "local"
    volumes:
      - ./config:/opt/hadoop/etc/hadoop
      - datanode-co-data:/data/datanode
    command: ["bash", "-c", "/etc/init.d/ssh start && hdfs datanode"]
    depends_on:
      namenode:
        condition: service_healthy

  client-co:
    image: hadoop-base:3.2.1
    container_name: client-co
    hostname: client-co
    networks:
      zona-co:
        ipv4_address: 172.20.3.100
    volumes:
      - ./config:/opt/hadoop/etc/hadoop
    command: ["bash", "-c", "/etc/init.d/ssh start && tail -f /dev/null"]

# ---------------------------------------------------
# DEFINICIÓN DE LAS REDES (ZONAS)
# ---------------------------------------------------
networks:
  zona-br:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.1.0/24
  zona-cl:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.2.0/24
  zona-co:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.3.0/24